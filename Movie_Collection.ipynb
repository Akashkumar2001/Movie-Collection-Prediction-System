{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e99a43",
   "metadata": {},
   "source": [
    "## Import ‘Movie_collection’ csv files in data_x and data_y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40765f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ‘Movie_collection’ csv files in data_x and data_y variables.\n",
    "data_x=pd.read_csv(r'C:\\Users\\akash\\Desktop\\course\\Deep Learning\\Assignment_4_data\\Movie_collection_Independent.csv',header=0)\n",
    "data_y=pd.read_csv('C:/Users/akash/Desktop/course/Deep Learning/Assignment_4_data/Movie_collection_Target.csv',header=0)\n",
    "data_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc771480",
   "metadata": {},
   "source": [
    "## Look at the shape and first five rows of both dataframes to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13b097ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the shape and first five rows of both dataframes to understand the data\n",
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7054e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marketin_expense</th>\n",
       "      <th>Production_expense</th>\n",
       "      <th>Multiplex_coverage</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Movie_length</th>\n",
       "      <th>Lead_ Actor_Rating</th>\n",
       "      <th>Lead_Actress_rating</th>\n",
       "      <th>Director_rating</th>\n",
       "      <th>Producer_rating</th>\n",
       "      <th>Critic_rating</th>\n",
       "      <th>Trailer_views</th>\n",
       "      <th>Time_taken</th>\n",
       "      <th>Twitter_hastags</th>\n",
       "      <th>Avg_age_actors</th>\n",
       "      <th>Num_multiplex</th>\n",
       "      <th>3D_available</th>\n",
       "      <th>Genre_Thriller</th>\n",
       "      <th>Genre_Drama</th>\n",
       "      <th>Genre_Comedy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.1264</td>\n",
       "      <td>59.62</td>\n",
       "      <td>0.462</td>\n",
       "      <td>36524.125</td>\n",
       "      <td>138.7</td>\n",
       "      <td>7.825</td>\n",
       "      <td>8.095</td>\n",
       "      <td>7.910</td>\n",
       "      <td>7.995</td>\n",
       "      <td>7.94</td>\n",
       "      <td>527367</td>\n",
       "      <td>109.60</td>\n",
       "      <td>223.840</td>\n",
       "      <td>23</td>\n",
       "      <td>494</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.5462</td>\n",
       "      <td>69.14</td>\n",
       "      <td>0.531</td>\n",
       "      <td>35668.655</td>\n",
       "      <td>152.4</td>\n",
       "      <td>7.505</td>\n",
       "      <td>7.650</td>\n",
       "      <td>7.440</td>\n",
       "      <td>7.470</td>\n",
       "      <td>7.44</td>\n",
       "      <td>494055</td>\n",
       "      <td>146.64</td>\n",
       "      <td>243.456</td>\n",
       "      <td>42</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.5458</td>\n",
       "      <td>69.14</td>\n",
       "      <td>0.531</td>\n",
       "      <td>39912.675</td>\n",
       "      <td>134.6</td>\n",
       "      <td>7.485</td>\n",
       "      <td>7.570</td>\n",
       "      <td>7.495</td>\n",
       "      <td>7.515</td>\n",
       "      <td>7.44</td>\n",
       "      <td>547051</td>\n",
       "      <td>147.88</td>\n",
       "      <td>2022.400</td>\n",
       "      <td>38</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.6474</td>\n",
       "      <td>59.36</td>\n",
       "      <td>0.542</td>\n",
       "      <td>38873.890</td>\n",
       "      <td>119.3</td>\n",
       "      <td>6.895</td>\n",
       "      <td>7.035</td>\n",
       "      <td>6.920</td>\n",
       "      <td>7.020</td>\n",
       "      <td>8.26</td>\n",
       "      <td>516279</td>\n",
       "      <td>185.36</td>\n",
       "      <td>225.344</td>\n",
       "      <td>45</td>\n",
       "      <td>472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.3810</td>\n",
       "      <td>59.36</td>\n",
       "      <td>0.542</td>\n",
       "      <td>39701.585</td>\n",
       "      <td>127.7</td>\n",
       "      <td>6.920</td>\n",
       "      <td>7.070</td>\n",
       "      <td>6.815</td>\n",
       "      <td>7.070</td>\n",
       "      <td>8.26</td>\n",
       "      <td>531448</td>\n",
       "      <td>176.48</td>\n",
       "      <td>225.792</td>\n",
       "      <td>55</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marketin_expense  Production_expense  Multiplex_coverage     Budget  \\\n",
       "0           20.1264               59.62               0.462  36524.125   \n",
       "1           20.5462               69.14               0.531  35668.655   \n",
       "2           20.5458               69.14               0.531  39912.675   \n",
       "3           20.6474               59.36               0.542  38873.890   \n",
       "4           21.3810               59.36               0.542  39701.585   \n",
       "\n",
       "   Movie_length  Lead_ Actor_Rating  Lead_Actress_rating  Director_rating  \\\n",
       "0         138.7               7.825                8.095            7.910   \n",
       "1         152.4               7.505                7.650            7.440   \n",
       "2         134.6               7.485                7.570            7.495   \n",
       "3         119.3               6.895                7.035            6.920   \n",
       "4         127.7               6.920                7.070            6.815   \n",
       "\n",
       "   Producer_rating  Critic_rating  Trailer_views  Time_taken  Twitter_hastags  \\\n",
       "0            7.995           7.94         527367      109.60          223.840   \n",
       "1            7.470           7.44         494055      146.64          243.456   \n",
       "2            7.515           7.44         547051      147.88         2022.400   \n",
       "3            7.020           8.26         516279      185.36          225.344   \n",
       "4            7.070           8.26         531448      176.48          225.792   \n",
       "\n",
       "   Avg_age_actors  Num_multiplex  3D_available  Genre_Thriller  Genre_Drama  \\\n",
       "0              23            494             1               1            0   \n",
       "1              42            462             0               0            1   \n",
       "2              38            458             0               0            0   \n",
       "3              45            472             1               0            1   \n",
       "4              55            395             0               0            1   \n",
       "\n",
       "   Genre_Comedy  \n",
       "0             0  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8f0250f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.106667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Collection\n",
       "0    2.266667\n",
       "1    2.106667\n",
       "2    2.980000\n",
       "3    2.893333\n",
       "4    3.080000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1d2fb",
   "metadata": {},
   "source": [
    "## Split the data into test, train, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f89424a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splits the dataset in the ratio of 3:1 or 75% and 25%\n",
    "\n",
    "X_train_full,X_test,y_train_full,y_test=train_test_split(data_x,data_y,random_state=42)\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train_full,y_train_full,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d257be",
   "metadata": {},
   "source": [
    "## Take a look at the shape of the test, train, and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4daa05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 19)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36f18ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 19)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e2d7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 19)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe47df",
   "metadata": {},
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "269c6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_valid=scaler.transform(X_valid)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7db1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400a39e",
   "metadata": {},
   "source": [
    "## Create an ANN model with 2 dense layers of 30 neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "703825bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation=\"relu\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30,activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7f58e",
   "metadata": {},
   "source": [
    "## Compile the model with loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-2) and metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2f5f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",\n",
    "             optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['mae'])\n",
    "# mae=mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f37cff",
   "metadata": {},
   "source": [
    "## Train the model for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f2943d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1101 - mae: 0.2472 - val_loss: 0.1355 - val_mae: 0.2809\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1099 - mae: 0.2467 - val_loss: 0.1350 - val_mae: 0.2803\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1096 - mae: 0.2466 - val_loss: 0.1347 - val_mae: 0.2799\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1093 - mae: 0.2463 - val_loss: 0.1343 - val_mae: 0.2794\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1091 - mae: 0.2460 - val_loss: 0.1340 - val_mae: 0.2790\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1089 - mae: 0.2458 - val_loss: 0.1337 - val_mae: 0.2786\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1086 - mae: 0.2454 - val_loss: 0.1334 - val_mae: 0.2782\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1083 - mae: 0.2454 - val_loss: 0.1332 - val_mae: 0.2780\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1081 - mae: 0.2449 - val_loss: 0.1329 - val_mae: 0.2777\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1079 - mae: 0.2448 - val_loss: 0.1326 - val_mae: 0.2772\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1076 - mae: 0.2445 - val_loss: 0.1324 - val_mae: 0.2769\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1074 - mae: 0.2441 - val_loss: 0.1321 - val_mae: 0.2766\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1072 - mae: 0.2440 - val_loss: 0.1319 - val_mae: 0.2763\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1070 - mae: 0.2436 - val_loss: 0.1315 - val_mae: 0.2759\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1066 - mae: 0.2433 - val_loss: 0.1312 - val_mae: 0.2755\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1065 - mae: 0.2433 - val_loss: 0.1311 - val_mae: 0.2753\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1063 - mae: 0.2427 - val_loss: 0.1308 - val_mae: 0.2749\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1060 - mae: 0.2426 - val_loss: 0.1306 - val_mae: 0.2747\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1058 - mae: 0.2422 - val_loss: 0.1303 - val_mae: 0.2743\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1055 - mae: 0.2419 - val_loss: 0.1300 - val_mae: 0.2739\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1054 - mae: 0.2417 - val_loss: 0.1296 - val_mae: 0.2734\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1051 - mae: 0.2415 - val_loss: 0.1294 - val_mae: 0.2732\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1049 - mae: 0.2414 - val_loss: 0.1292 - val_mae: 0.2728\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1047 - mae: 0.2410 - val_loss: 0.1290 - val_mae: 0.2725\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1045 - mae: 0.2407 - val_loss: 0.1287 - val_mae: 0.2722\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1043 - mae: 0.2406 - val_loss: 0.1285 - val_mae: 0.2719\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1041 - mae: 0.2403 - val_loss: 0.1282 - val_mae: 0.2716\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1039 - mae: 0.2401 - val_loss: 0.1279 - val_mae: 0.2712\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1036 - mae: 0.2399 - val_loss: 0.1277 - val_mae: 0.2709\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1035 - mae: 0.2398 - val_loss: 0.1275 - val_mae: 0.2706\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1032 - mae: 0.2391 - val_loss: 0.1271 - val_mae: 0.2701\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1030 - mae: 0.2390 - val_loss: 0.1268 - val_mae: 0.2697\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1028 - mae: 0.2388 - val_loss: 0.1265 - val_mae: 0.2693\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.1026 - mae: 0.2389 - val_loss: 0.1264 - val_mae: 0.2691\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1024 - mae: 0.2385 - val_loss: 0.1261 - val_mae: 0.2688\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1022 - mae: 0.2380 - val_loss: 0.1259 - val_mae: 0.2684\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1020 - mae: 0.2377 - val_loss: 0.1256 - val_mae: 0.2681\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1017 - mae: 0.2376 - val_loss: 0.1255 - val_mae: 0.2678\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1016 - mae: 0.2374 - val_loss: 0.1252 - val_mae: 0.2675\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1014 - mae: 0.2371 - val_loss: 0.1250 - val_mae: 0.2672\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1013 - mae: 0.2371 - val_loss: 0.1249 - val_mae: 0.2670\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1011 - mae: 0.2366 - val_loss: 0.1246 - val_mae: 0.2666\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.1008 - mae: 0.2366 - val_loss: 0.1244 - val_mae: 0.2664\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1007 - mae: 0.2364 - val_loss: 0.1243 - val_mae: 0.2662\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1004 - mae: 0.2360 - val_loss: 0.1240 - val_mae: 0.2659\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1003 - mae: 0.2359 - val_loss: 0.1239 - val_mae: 0.2656\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1001 - mae: 0.2357 - val_loss: 0.1237 - val_mae: 0.2654\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0999 - mae: 0.2352 - val_loss: 0.1235 - val_mae: 0.2651\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0997 - mae: 0.2353 - val_loss: 0.1232 - val_mae: 0.2648\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0995 - mae: 0.2348 - val_loss: 0.1230 - val_mae: 0.2645\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0994 - mae: 0.2347 - val_loss: 0.1227 - val_mae: 0.2640\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0992 - mae: 0.2346 - val_loss: 0.1226 - val_mae: 0.2638\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0990 - mae: 0.2344 - val_loss: 0.1224 - val_mae: 0.2636\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0989 - mae: 0.2340 - val_loss: 0.1221 - val_mae: 0.2632\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0987 - mae: 0.2339 - val_loss: 0.1219 - val_mae: 0.2629\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0986 - mae: 0.2339 - val_loss: 0.1218 - val_mae: 0.2627\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0983 - mae: 0.2334 - val_loss: 0.1216 - val_mae: 0.2624\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0981 - mae: 0.2331 - val_loss: 0.1214 - val_mae: 0.2622\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0980 - mae: 0.2331 - val_loss: 0.1213 - val_mae: 0.2619\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0978 - mae: 0.2329 - val_loss: 0.1212 - val_mae: 0.2618\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0976 - mae: 0.2326 - val_loss: 0.1210 - val_mae: 0.2616\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0975 - mae: 0.2323 - val_loss: 0.1208 - val_mae: 0.2612\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0973 - mae: 0.2321 - val_loss: 0.1206 - val_mae: 0.2610\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0971 - mae: 0.2318 - val_loss: 0.1205 - val_mae: 0.2608\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0970 - mae: 0.2316 - val_loss: 0.1203 - val_mae: 0.2605\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0968 - mae: 0.2314 - val_loss: 0.1200 - val_mae: 0.2601\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0966 - mae: 0.2315 - val_loss: 0.1199 - val_mae: 0.2599\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0964 - mae: 0.2312 - val_loss: 0.1198 - val_mae: 0.2597\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0964 - mae: 0.2310 - val_loss: 0.1196 - val_mae: 0.2595\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0961 - mae: 0.2307 - val_loss: 0.1194 - val_mae: 0.2593\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0961 - mae: 0.2306 - val_loss: 0.1192 - val_mae: 0.2589\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0958 - mae: 0.2303 - val_loss: 0.1191 - val_mae: 0.2587\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0956 - mae: 0.2300 - val_loss: 0.1189 - val_mae: 0.2585\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0954 - mae: 0.2298 - val_loss: 0.1187 - val_mae: 0.2582\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0953 - mae: 0.2296 - val_loss: 0.1186 - val_mae: 0.2580\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0952 - mae: 0.2294 - val_loss: 0.1183 - val_mae: 0.2576\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0950 - mae: 0.2294 - val_loss: 0.1181 - val_mae: 0.2573\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0949 - mae: 0.2292 - val_loss: 0.1181 - val_mae: 0.2573\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0947 - mae: 0.2290 - val_loss: 0.1180 - val_mae: 0.2572\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0945 - mae: 0.2288 - val_loss: 0.1179 - val_mae: 0.2569\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0944 - mae: 0.2285 - val_loss: 0.1177 - val_mae: 0.2566\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0943 - mae: 0.2285 - val_loss: 0.1175 - val_mae: 0.2564\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0940 - mae: 0.2282 - val_loss: 0.1174 - val_mae: 0.2562\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0939 - mae: 0.2278 - val_loss: 0.1172 - val_mae: 0.2559\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0938 - mae: 0.2278 - val_loss: 0.1171 - val_mae: 0.2557\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0936 - mae: 0.2276 - val_loss: 0.1169 - val_mae: 0.2555\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0934 - mae: 0.2273 - val_loss: 0.1168 - val_mae: 0.2553\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0933 - mae: 0.2272 - val_loss: 0.1166 - val_mae: 0.2550\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0931 - mae: 0.2269 - val_loss: 0.1165 - val_mae: 0.2548\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0930 - mae: 0.2268 - val_loss: 0.1164 - val_mae: 0.2547\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0928 - mae: 0.2265 - val_loss: 0.1162 - val_mae: 0.2544\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0928 - mae: 0.2264 - val_loss: 0.1160 - val_mae: 0.2540\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0926 - mae: 0.2262 - val_loss: 0.1158 - val_mae: 0.2538\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0925 - mae: 0.2263 - val_loss: 0.1159 - val_mae: 0.2539\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0923 - mae: 0.2259 - val_loss: 0.1158 - val_mae: 0.2536\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0921 - mae: 0.2255 - val_loss: 0.1156 - val_mae: 0.2534\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0920 - mae: 0.2254 - val_loss: 0.1154 - val_mae: 0.2531\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0919 - mae: 0.2254 - val_loss: 0.1153 - val_mae: 0.2529\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0917 - mae: 0.2250 - val_loss: 0.1152 - val_mae: 0.2527\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0916 - mae: 0.2249 - val_loss: 0.1150 - val_mae: 0.2525\n"
     ]
    }
   ],
   "source": [
    "model_history=model.fit(X_train,y_train,epochs=100,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a82581",
   "metadata": {},
   "source": [
    "## Evaluate the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab4c8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4137 - mae: 0.3356\n"
     ]
    }
   ],
   "source": [
    "mae_test=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df6224b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.11005809158086777,\n",
       "  0.10985172539949417,\n",
       "  0.1095711812376976,\n",
       "  0.10932521522045135,\n",
       "  0.10905466228723526,\n",
       "  0.10889730602502823,\n",
       "  0.10860476642847061,\n",
       "  0.1083221510052681,\n",
       "  0.10811761021614075,\n",
       "  0.10794322937726974,\n",
       "  0.10759515315294266,\n",
       "  0.10740941762924194,\n",
       "  0.10718376189470291,\n",
       "  0.10697422176599503,\n",
       "  0.10662733018398285,\n",
       "  0.10651474446058273,\n",
       "  0.10626053065061569,\n",
       "  0.10602658241987228,\n",
       "  0.10580618679523468,\n",
       "  0.10551999509334564,\n",
       "  0.10538050532341003,\n",
       "  0.10511894524097443,\n",
       "  0.10488878190517426,\n",
       "  0.10469617694616318,\n",
       "  0.10446460545063019,\n",
       "  0.10425997525453568,\n",
       "  0.10407693684101105,\n",
       "  0.10392523556947708,\n",
       "  0.10363101214170456,\n",
       "  0.10347111523151398,\n",
       "  0.10319584608078003,\n",
       "  0.10302841663360596,\n",
       "  0.10278142243623734,\n",
       "  0.10264667123556137,\n",
       "  0.10240933299064636,\n",
       "  0.10217762738466263,\n",
       "  0.1020205020904541,\n",
       "  0.1017497330904007,\n",
       "  0.10157864540815353,\n",
       "  0.10141970962285995,\n",
       "  0.10128100961446762,\n",
       "  0.10106392204761505,\n",
       "  0.10083583742380142,\n",
       "  0.10070530325174332,\n",
       "  0.10044663399457932,\n",
       "  0.10026957839727402,\n",
       "  0.10014933347702026,\n",
       "  0.09991301596164703,\n",
       "  0.09974126517772675,\n",
       "  0.09952059388160706,\n",
       "  0.09943170845508575,\n",
       "  0.09919394552707672,\n",
       "  0.09903773665428162,\n",
       "  0.09885035455226898,\n",
       "  0.09868484735488892,\n",
       "  0.09858544915914536,\n",
       "  0.09833788871765137,\n",
       "  0.09811819344758987,\n",
       "  0.09796282649040222,\n",
       "  0.09779170900583267,\n",
       "  0.09757932275533676,\n",
       "  0.09749297052621841,\n",
       "  0.09729868918657303,\n",
       "  0.09706567227840424,\n",
       "  0.09701612591743469,\n",
       "  0.0967642143368721,\n",
       "  0.09661468863487244,\n",
       "  0.09643784165382385,\n",
       "  0.09636522829532623,\n",
       "  0.09610169380903244,\n",
       "  0.09606409072875977,\n",
       "  0.09580197185277939,\n",
       "  0.09564836323261261,\n",
       "  0.095433808863163,\n",
       "  0.0952608585357666,\n",
       "  0.09516219049692154,\n",
       "  0.0949847400188446,\n",
       "  0.09486360102891922,\n",
       "  0.09467864781618118,\n",
       "  0.09453469514846802,\n",
       "  0.09438981860876083,\n",
       "  0.09425922483205795,\n",
       "  0.09404905885457993,\n",
       "  0.09393646568059921,\n",
       "  0.09377060830593109,\n",
       "  0.0936230793595314,\n",
       "  0.09341420233249664,\n",
       "  0.09334410727024078,\n",
       "  0.09311767667531967,\n",
       "  0.09299923479557037,\n",
       "  0.09284479171037674,\n",
       "  0.09277952462434769,\n",
       "  0.09255628287792206,\n",
       "  0.09249022603034973,\n",
       "  0.09230650961399078,\n",
       "  0.09210657328367233,\n",
       "  0.09197081625461578,\n",
       "  0.09192505478858948,\n",
       "  0.09168846160173416,\n",
       "  0.0915571004152298],\n",
       " 'mae': [0.2471579760313034,\n",
       "  0.2467474639415741,\n",
       "  0.24656817317008972,\n",
       "  0.2462623417377472,\n",
       "  0.24602825939655304,\n",
       "  0.24576950073242188,\n",
       "  0.24543581902980804,\n",
       "  0.2453804761171341,\n",
       "  0.24492408335208893,\n",
       "  0.24483683705329895,\n",
       "  0.24451479315757751,\n",
       "  0.2441335916519165,\n",
       "  0.2439853549003601,\n",
       "  0.2436404675245285,\n",
       "  0.24328188598155975,\n",
       "  0.24334478378295898,\n",
       "  0.2426944524049759,\n",
       "  0.24260564148426056,\n",
       "  0.2422126680612564,\n",
       "  0.24187375605106354,\n",
       "  0.24165134131908417,\n",
       "  0.24146808683872223,\n",
       "  0.24135325849056244,\n",
       "  0.2410200983285904,\n",
       "  0.24073907732963562,\n",
       "  0.24055996537208557,\n",
       "  0.2403467446565628,\n",
       "  0.24013124406337738,\n",
       "  0.2398880124092102,\n",
       "  0.239756241440773,\n",
       "  0.23911376297473907,\n",
       "  0.23902033269405365,\n",
       "  0.23876836895942688,\n",
       "  0.2389048933982849,\n",
       "  0.2385333627462387,\n",
       "  0.2380412518978119,\n",
       "  0.23772269487380981,\n",
       "  0.23764440417289734,\n",
       "  0.2374352663755417,\n",
       "  0.23710723221302032,\n",
       "  0.237095907330513,\n",
       "  0.23655004799365997,\n",
       "  0.23664554953575134,\n",
       "  0.23639662563800812,\n",
       "  0.23596175014972687,\n",
       "  0.23585212230682373,\n",
       "  0.23567162454128265,\n",
       "  0.23521313071250916,\n",
       "  0.23527677357196808,\n",
       "  0.23483531177043915,\n",
       "  0.2347448170185089,\n",
       "  0.2345830351114273,\n",
       "  0.23441143333911896,\n",
       "  0.23400312662124634,\n",
       "  0.23388123512268066,\n",
       "  0.23390471935272217,\n",
       "  0.23336674273014069,\n",
       "  0.23314432799816132,\n",
       "  0.2330748587846756,\n",
       "  0.23286187648773193,\n",
       "  0.23257432878017426,\n",
       "  0.2323288917541504,\n",
       "  0.2320908010005951,\n",
       "  0.23184511065483093,\n",
       "  0.23155666887760162,\n",
       "  0.23137731850147247,\n",
       "  0.23147636651992798,\n",
       "  0.23115961253643036,\n",
       "  0.2309633493423462,\n",
       "  0.23069773614406586,\n",
       "  0.23057317733764648,\n",
       "  0.2303454428911209,\n",
       "  0.2300407737493515,\n",
       "  0.22983185946941376,\n",
       "  0.22962586581707,\n",
       "  0.2294113039970398,\n",
       "  0.22935087978839874,\n",
       "  0.2291753739118576,\n",
       "  0.2290392816066742,\n",
       "  0.2287503033876419,\n",
       "  0.22849568724632263,\n",
       "  0.22846171259880066,\n",
       "  0.22820861637592316,\n",
       "  0.22783353924751282,\n",
       "  0.22782593965530396,\n",
       "  0.22761270403862,\n",
       "  0.22731225192546844,\n",
       "  0.22716492414474487,\n",
       "  0.2269088327884674,\n",
       "  0.22678767144680023,\n",
       "  0.22653095424175262,\n",
       "  0.22638294100761414,\n",
       "  0.22617831826210022,\n",
       "  0.22632157802581787,\n",
       "  0.22585266828536987,\n",
       "  0.22551292181015015,\n",
       "  0.22536030411720276,\n",
       "  0.22542402148246765,\n",
       "  0.2250342220067978,\n",
       "  0.22487041354179382],\n",
       " 'val_loss': [0.1355394423007965,\n",
       "  0.13504457473754883,\n",
       "  0.13472671806812286,\n",
       "  0.13434959948062897,\n",
       "  0.1340271532535553,\n",
       "  0.1336612105369568,\n",
       "  0.13335351645946503,\n",
       "  0.13318610191345215,\n",
       "  0.1329188048839569,\n",
       "  0.13255825638771057,\n",
       "  0.13236354291439056,\n",
       "  0.13210023939609528,\n",
       "  0.13185366988182068,\n",
       "  0.13153839111328125,\n",
       "  0.13123932480812073,\n",
       "  0.131064772605896,\n",
       "  0.13078968226909637,\n",
       "  0.1305759996175766,\n",
       "  0.13030092418193817,\n",
       "  0.12996923923492432,\n",
       "  0.12959860265254974,\n",
       "  0.12942782044410706,\n",
       "  0.12917175889015198,\n",
       "  0.1289636492729187,\n",
       "  0.12871725857257843,\n",
       "  0.12847523391246796,\n",
       "  0.12821230292320251,\n",
       "  0.12791985273361206,\n",
       "  0.12768837809562683,\n",
       "  0.12749196588993073,\n",
       "  0.12709647417068481,\n",
       "  0.12679147720336914,\n",
       "  0.12651947140693665,\n",
       "  0.1264217644929886,\n",
       "  0.12614262104034424,\n",
       "  0.1258920580148697,\n",
       "  0.12562069296836853,\n",
       "  0.12545014917850494,\n",
       "  0.12524403631687164,\n",
       "  0.12498454004526138,\n",
       "  0.12485353648662567,\n",
       "  0.12456540763378143,\n",
       "  0.12441586703062057,\n",
       "  0.12427661567926407,\n",
       "  0.12403188645839691,\n",
       "  0.12386246025562286,\n",
       "  0.12371406704187393,\n",
       "  0.12346392869949341,\n",
       "  0.12323667854070663,\n",
       "  0.12303199619054794,\n",
       "  0.12273236364126205,\n",
       "  0.12256159633398056,\n",
       "  0.12240945547819138,\n",
       "  0.12212343513965607,\n",
       "  0.12194393575191498,\n",
       "  0.12184377014636993,\n",
       "  0.12163697928190231,\n",
       "  0.12144158780574799,\n",
       "  0.12126380205154419,\n",
       "  0.12116105109453201,\n",
       "  0.12103259563446045,\n",
       "  0.12080102413892746,\n",
       "  0.12063399702310562,\n",
       "  0.12046975642442703,\n",
       "  0.12026112526655197,\n",
       "  0.11999332904815674,\n",
       "  0.11989529430866241,\n",
       "  0.1197817325592041,\n",
       "  0.11963754147291183,\n",
       "  0.11944767087697983,\n",
       "  0.11919742077589035,\n",
       "  0.11908380687236786,\n",
       "  0.11889682710170746,\n",
       "  0.11871147900819778,\n",
       "  0.11855922639369965,\n",
       "  0.11831372231245041,\n",
       "  0.11813522130250931,\n",
       "  0.1181037500500679,\n",
       "  0.11804627627134323,\n",
       "  0.11789073050022125,\n",
       "  0.1176934465765953,\n",
       "  0.11754042655229568,\n",
       "  0.1174117848277092,\n",
       "  0.11721029132604599,\n",
       "  0.11709117889404297,\n",
       "  0.11694125831127167,\n",
       "  0.11681085079908371,\n",
       "  0.11661145836114883,\n",
       "  0.11648982018232346,\n",
       "  0.116436667740345,\n",
       "  0.11622191965579987,\n",
       "  0.1159662976861,\n",
       "  0.1158224418759346,\n",
       "  0.115891233086586,\n",
       "  0.11576366424560547,\n",
       "  0.11558178067207336,\n",
       "  0.11537209898233414,\n",
       "  0.11526269465684891,\n",
       "  0.11516070365905762,\n",
       "  0.11502834409475327],\n",
       " 'val_mae': [0.280917227268219,\n",
       "  0.2803035080432892,\n",
       "  0.27991771697998047,\n",
       "  0.2794439196586609,\n",
       "  0.27904385328292847,\n",
       "  0.2785853445529938,\n",
       "  0.27819862961769104,\n",
       "  0.27798983454704285,\n",
       "  0.2776554226875305,\n",
       "  0.27718910574913025,\n",
       "  0.27694135904312134,\n",
       "  0.27661213278770447,\n",
       "  0.2762940227985382,\n",
       "  0.2758878767490387,\n",
       "  0.2755063772201538,\n",
       "  0.27528026700019836,\n",
       "  0.2749346196651459,\n",
       "  0.27466678619384766,\n",
       "  0.2743103504180908,\n",
       "  0.2738749086856842,\n",
       "  0.27338677644729614,\n",
       "  0.27316293120384216,\n",
       "  0.2728240191936493,\n",
       "  0.2725466787815094,\n",
       "  0.2722257077693939,\n",
       "  0.2719048857688904,\n",
       "  0.2715546190738678,\n",
       "  0.27116647362709045,\n",
       "  0.2708602249622345,\n",
       "  0.2705993056297302,\n",
       "  0.27006804943084717,\n",
       "  0.26965203881263733,\n",
       "  0.26928403973579407,\n",
       "  0.26914969086647034,\n",
       "  0.26877132058143616,\n",
       "  0.2684333920478821,\n",
       "  0.26806336641311646,\n",
       "  0.2678288221359253,\n",
       "  0.2675464451313019,\n",
       "  0.2671984136104584,\n",
       "  0.26701101660728455,\n",
       "  0.26661553978919983,\n",
       "  0.26640424132347107,\n",
       "  0.26620835065841675,\n",
       "  0.2658643126487732,\n",
       "  0.26562511920928955,\n",
       "  0.2654135525226593,\n",
       "  0.2650724947452545,\n",
       "  0.2647534906864166,\n",
       "  0.26445937156677246,\n",
       "  0.264030784368515,\n",
       "  0.2637821137905121,\n",
       "  0.263558030128479,\n",
       "  0.263155996799469,\n",
       "  0.26289328932762146,\n",
       "  0.2627391219139099,\n",
       "  0.2624499201774597,\n",
       "  0.262176513671875,\n",
       "  0.2619152367115021,\n",
       "  0.2617589235305786,\n",
       "  0.26156365871429443,\n",
       "  0.26123058795928955,\n",
       "  0.26099368929862976,\n",
       "  0.26075974106788635,\n",
       "  0.26045235991477966,\n",
       "  0.26007649302482605,\n",
       "  0.25992482900619507,\n",
       "  0.2597464323043823,\n",
       "  0.25953325629234314,\n",
       "  0.2592594623565674,\n",
       "  0.258897066116333,\n",
       "  0.25872111320495605,\n",
       "  0.25845280289649963,\n",
       "  0.25817859172821045,\n",
       "  0.25795429944992065,\n",
       "  0.25759831070899963,\n",
       "  0.25733065605163574,\n",
       "  0.2572668194770813,\n",
       "  0.25716227293014526,\n",
       "  0.256931334733963,\n",
       "  0.25664234161376953,\n",
       "  0.25642257928848267,\n",
       "  0.2562258243560791,\n",
       "  0.25593021512031555,\n",
       "  0.2557431757450104,\n",
       "  0.25551459193229675,\n",
       "  0.25530770421028137,\n",
       "  0.25501033663749695,\n",
       "  0.2548134922981262,\n",
       "  0.25471413135528564,\n",
       "  0.2543928921222687,\n",
       "  0.25401344895362854,\n",
       "  0.2537892460823059,\n",
       "  0.25385603308677673,\n",
       "  0.2536499798297882,\n",
       "  0.2533741295337677,\n",
       "  0.2530616819858551,\n",
       "  0.25288277864456177,\n",
       "  0.25270941853523254,\n",
       "  0.2525117099285126]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccbbf1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model_history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479ec32",
   "metadata": {},
   "source": [
    "## Predict the values of the first 5 test records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8be57da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0050d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5451803]\n",
      " [2.551341 ]\n",
      " [1.89748  ]\n",
      " [2.282321 ]\n",
      " [1.6840097]]\n",
      "     Collection\n",
      "173    2.240000\n",
      "274    2.826667\n",
      "491    1.573333\n",
      "72     2.186667\n",
      "452    1.740000\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_new)\n",
    "print(y_pred)  #Predicted values\n",
    "print(y_test[:5]) #Original Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7e764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
